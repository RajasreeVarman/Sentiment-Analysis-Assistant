{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RajasreeVarman/Sentiment-Analysis-Assistant/blob/main/new_senti.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umeub46TcW4Q"
      },
      "outputs": [],
      "source": [
        "!pip install transformers -q\n",
        "!pip install -U gradio\n",
        "!pip install -q -U google-generativeai\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "# Used to securely store your API key\n",
        "from google.colab import userdata\n",
        "\n",
        "#Its use pre trained model to convert the speech to text\n",
        "asr = pipeline(\"automatic-speech-recognition\", \"openai/whisper-base\")\n",
        "#this pipeline for classify text into different categories(postive/negative)\n",
        "\n",
        "\n",
        "#get the api key from secrets\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "#select the model to use\n",
        "model = genai.GenerativeModel('gemini-pro')\n",
        "\n",
        "#defining Functions\n",
        "\n",
        "def speech_to_text(speech):\n",
        "    text = asr(speech)[\"text\"]\n",
        "    return text\n",
        "\n",
        "\n",
        "def text_to_sentiment(text):\n",
        "  classifier_template = f\"\"\"You are a conversation sentiment analyser bot which will read conversation texts and classify the percentage of positive\\\n",
        "   and negative sentiments depicted in the conversation make fornt of postive and negative bold . The conversation is: {text} The response format should be like: Positive: % \\n Negative: %.\\\n",
        "    Also specify the positive and negative points seperately.\"\"\"\n",
        "  response = model.generate_content(classifier_template)\n",
        "  return response.text\n",
        "'''    return classifier(text)[0][\"label\"]\n",
        "'''\n",
        "\n",
        "\n",
        "def summarize_conv(text):\n",
        "  prompt_template = f\"\"\"Summarize the customer call feedback and identify the areas for improvement and give the output in tabular format make one column for problem\\\n",
        "  and one column for problem suggestions and make one more column for suggest the area of improvement to the particular department name that column as Department to notify . : {text}\"\"\"\n",
        "  response = model.generate_content(prompt_template)\n",
        "  return response.text\n",
        "\n",
        "\n",
        "\n",
        "#Creating gradio demo\n",
        "\n",
        "demo = gr.Blocks(theme='shivi/calm_seafoam', title='Sentiment Analysis Assistant')\n",
        "\n",
        "with demo:\n",
        "  with gr.Row():\n",
        "    audio_file = gr.Audio(type=\"filepath\")\n",
        "    text = gr.Textbox()\n",
        "  b1 = gr.Button(\"Transcribe Audio\")\n",
        "  label = gr.Markdown()\n",
        "  b2 = gr.Button(\"Classify Sentiment\")\n",
        "  text2 = gr.Markdown()\n",
        "  b3 = gr.Button(\"Summarize the conversation\")\n",
        "  b1.click(speech_to_text, inputs=audio_file, outputs=text)\n",
        "  b2.click(text_to_sentiment, inputs=text, outputs=label)\n",
        "  b3.click(summarize_conv, inputs=text, outputs=text2)\n",
        "\n",
        "demo.launch(debug =True, share = True)"
      ],
      "metadata": {
        "id": "aECa7xJLRQtp",
        "outputId": "993ebe1c-f3dc-43aa-c668-4b42042f94c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://70ac5104e53d5e813f.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://70ac5104e53d5e813f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOvbTUWK/AZd6W3gFDUs2n8",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}